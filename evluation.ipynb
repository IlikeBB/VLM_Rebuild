{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import signal\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "from main import Main__\n",
    "\n",
    "model_config = {'amp':True, 'use_distributed':False,'accum_grad_iters':1,\n",
    "                'batch_size':4,\n",
    "                'chat_template': True, \n",
    "                'end_sym': [\n",
    "                    '\\n {} </s>',\n",
    "                    \"\\n <|start_header_id|>assistant<|end_header_id|> {} <|eot_id|>\"\n",
    "                ],# list[0] = llama2, list[1] = llama3\n",
    "                'prompt_template': [\n",
    "                \"<s>[INST] {} [/INST]\", \n",
    "                \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|> {} <|eot_id|>\"\"\"\n",
    "                ],# list[0] = llama2, list[1] = llama3\n",
    "                'max_txt_len': 1024, 'max_context_len': 3500,\n",
    "                'ouput_dir': './model_FT_weight/llama3_vit_L-clip336', #./llama3_vit_L-clip336, ./llama3_vit_B-clip224-b16\n",
    "                # 'ouput_dir': './demo', #./llama3_vit_L-clip336, ./llama3_vit_B-clip224-b16\n",
    "                'stage_ckpt': '/ssd3/chih/LLM/MiniGPT-4-ckpt/checkpoint_stage3.pth', \n",
    "                'vis_root_train': './dataset/minigpt_casing_train/coco/image/train',\n",
    "                'ann_paths_train': ['./dataset/minigpt_casing_train/coco_caption/defe_ready_anno.json'],\n",
    "                'vis_root_valid': './dataset/minigpt_casing_test/coco/image/test',\n",
    "                'ann_paths_valid': ['./dataset/minigpt_casing_test/coco_caption/defe_ready_anno.json']}\n",
    "\n",
    "# llm_config = {'llama_model':'/ssd3/chih/LLM/Llama-2-7b-chat-hf', 'low_resource':True, 'low_res_device':0, \n",
    "#               'lora_r':64, 'lora_target_modules':[\"q_proj\", \"v_proj\"], 'lora_alpha':16,'lora_dropout':0.05\n",
    "#               }\n",
    "llm_config = {'llama_model':'/ssd3/chih/LLM/Meta-Llama-3-8B-Instruct', 'low_resource':True, 'low_res_device':0, \n",
    "              'lora_r':64, 'lora_target_modules':[\"q_proj\", \"v_proj\"], 'lora_alpha':16,'lora_dropout':0.05\n",
    "              }\n",
    "# '/ssd3/chih/LLM/Meta-Llama-3-8B-Instruct'\n",
    "\n",
    "\n",
    "vit_config = {'model_name':'clip_large_336', #eva_clip_g, clip_large_336\n",
    "            #   'model_path':\"../../VITModel/clip-vit-base-patch16\", #clip-vit-base-patch16, clip-vit-large-patch14-336\n",
    "              'model_path':\"../../VITModel/clip-vit-large-patch14-336\", #clip-vit-base-patch16, clip-vit-large-patch14-336\n",
    "            #   'image_size': 224,  #bilp2 = 448, clip = 224 or 336\n",
    "              'image_size': 336,  #bilp2 = 448, clip = 224 or 336\n",
    "              'drop_path_rate': 0, 'use_grad_checkpoint': True, 'vit_precision': 'fp16', 'freeze_vit': True, }\n",
    "\n",
    "lr_config = {'init_lr': 1e-5, 'beta2':0.999,'min_lr': 1e-6, 'decay_rate': None, 'weight_decay':0.05,\n",
    "                'warmup_start_lr': 1e-6, 'warmup_steps': 1000, 'iters_per_epoch': 1000}\n",
    "\n",
    "\n",
    "main_ = Main__(model_config=model_config)\n",
    "main_.VLM_build(llm_config=llm_config, vit_config=vit_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.caption_datasets import COCOCaptionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "# demo測試對話反饋\n",
    "train_data_set = COCOCaptionDataset(vis_root = model_config['vis_root_train'], \n",
    "                                ann_paths = model_config['ann_paths_train'],\n",
    "                                img_size = vit_config['image_size'])\n",
    "dataloader = DataLoader(train_data_set, batch_size=1, num_workers=5, shuffle=True, pin_memory=True)\n",
    "ckpt_url = '/ssd3/chih/branch/VLM_Rebuild/model_FT_weight/llama3_vit_L-clip336/checkpoint_best.pth' \n",
    "main_.load_checkpoint(ckpt_url=ckpt_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_.model.llama_model.generation_config.pad_token_id = main_.model.llama_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# ====================Prompt Format====================\n",
    "patterns = [\"Llama-3\", \"Llama3\", \"llama3\", \"llama-3\"]\n",
    "pattern = re.compile(\"|\".join(patterns), flags=re.IGNORECASE)\n",
    "if pattern.search(main_.llm_config['llama_model']):\n",
    "    main_.prompt_template = main_.prompt_template[1]\n",
    "    main_.end_sym = main_.end_sym[1]\n",
    "else:\n",
    "    main_.prompt_template = main_.prompt_template[0]\n",
    "    main_.end_sym = main_.end_sym[0]\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(dataloader))\n",
    "samples['image'] = samples['image'].cuda()\n",
    "ans = main_.chat_module(samples=samples)\n",
    "ans = [text.split(\"<|end_header_id|> \")[1].replace(\" <|eot_id|>\",\"\") for text in ans]\n",
    "print(\"讀取使用fine tune後的llama3權重直接輸出 [同資料集finetune]\")\n",
    "print(\"Q:\",samples['instruction_input'], \"answer:\",samples['answer'])\n",
    "print(\"A:\",ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minigptv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
